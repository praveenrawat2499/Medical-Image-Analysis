# -*- coding: utf-8 -*-
"""BrainTumor_Detecting_MRI_images_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sHpXs5MZF9rRtIC2vxMjrx9HAHhOxd-n

# **Brain Tumor Detection by MRI Images**
"""

import warnings
warnings.filterwarnings('ignore')

!unzip "/content/drive/MyDrive/Brain Tumor MRI Images.zip"

"""## Importing Libraries"""

import numpy as np
import matplotlib.pyplot as plt
import os   #for files and dir
import math
import shutil #we can move file from one file to another
import glob

import tensorflow as tf
from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D
from keras.models import Sequential
from keras.models import Model, load_model
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import keras
import seaborn as sns

from keras.layers import Flatten, Dense 
from keras.applications.mobilenet import MobileNet, preprocess_input
from sklearn.metrics import accuracy_score, classification_report

#count the no of images in the respective classes 0 - NO Brain Tumor and 1 - Brain Tumor
ROOT_DIR = "/content/brain_tumor_dataset"
num_of_images = {}
for dir in os.listdir(ROOT_DIR):
  num_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR, dir)))

num_of_images.items()

os.listdir("/content/brain_tumor_dataset")

"""# we will split the data:
* 70% for training
* 15% for validation
* 15% for testing
"""

#we create a training folder
def dataFolder(p, split):
  
  if not os.path.exists("./"+p):
    os.mkdir("./"+p)

    for dir in os.listdir(ROOT_DIR):
      os.makedirs("./"+p+"/"+dir)

      for img in np.random.choice(a = os.listdir(os.path.join(ROOT_DIR, dir)),
                                  size = (math.floor(split*num_of_images[dir])-5),
                                  replace=False ):
        O = os.path.join(ROOT_DIR,dir,img) #path
        D = os.path.join("./"+p,dir) 
        shutil.copy(O,D) 
        os.remove(O)
  else:
    print(f"{p} folder exsist")

dataFolder("train", 0.7) #new training folder

dataFolder("val", 0.15) #new validation folder

dataFolder("test", 0.15) #new testing folder

"""## Model Building"""



"""### Preparing our data using Data Generator"""

def preprocessImages1(path):
  """
  input : Path
  output : Pre processed images    """
  image_data = ImageDataGenerator(zoom_range= 0.2, shear_range = 0.2, preprocessing_function= preprocess_input, horizontal_flip= True) #data augmentation
  image = image_data.flow_from_directory(directory = path, target_size = (224,224), batch_size = 32, class_mode = 'binary')
  
  return image

path = "/content/train"
train_data = preprocessImages1(path)

def preprocessImages2(path):
  
  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)
  image = image_data.flow_from_directory(directory = path, target_size = (224,224), batch_size = 32, class_mode = 'binary')
  
  return image

path = "/content/test"
test_data = preprocessImages2(path)

path = "/content/val"
val_data = preprocessImages2(path)

"""#Model Training"""

base_model = MobileNet(input_shape=(224,224,3), include_top= False)

for layer in base_model.layers:
  layer.trainable = False

# base_model.summary()

X = Flatten()(base_model.output)
X = Dense(units = 1, activation='sigmoid')(X)

model = Model(base_model.input, X)

model.summary()

"""### Compiling the model"""

model.compile(optimizer='rmsprop', loss = keras.losses.binary_crossentropy, metrics = ['accuracy'])

#Early stoping and model check point
from keras.callbacks import  ModelCheckpoint, EarlyStopping

from keras.models import Model
#early stopping
es = EarlyStopping(monitor="val_accuracy", min_delta=0.01, patience=5, verbose= 1)

#model check point
mc = ModelCheckpoint(monitor="val_accuracy", filepath="BrainTumor_model.h5", verbose= 1, save_best_only= True)

cd= [es,mc]

EPOCH = 20
VALID = 16

"""## Training model


"""

hs = model.fit_generator(train_data, 
                        #  steps_per_epoch= 8, 
                         epochs= 30, 
                         verbose= 1, 
                         validation_data = val_data, 
                        #  validation_steps= VALID, 
                         callbacks= cd)

"""#Model Accuracy"""

# #Model Accuracy
# from keras.models import load_model
# model = load_model("/content/drive/MyDrive/bestmodel.h5")

acc = model.evaluate_generator(test_data)[1]
print(f"the accuracy of our model is {acc*100} %")



#Model Graphical Interpretation
h = hs.history
h.keys()

import matplotlib.pyplot as plt
plt.plot(h['accuracy'])
plt.plot(h['val_accuracy'], c = "red")

plt.title("acc vs val-acc")
plt.show()

import matplotlib.pyplot as plt
plt.plot(h['loss'])
plt.plot(h['val_loss'], c = "red")

plt.title("loss vs val-loss")
plt.show()

CLASS_NAMES = list(train_data.class_indices.keys())
CLASS_NAMES

predictions = np.argmax(model.predict(test_data), axis=1)

acc = accuracy_score(test_data.labels, predictions)
cm = tf.math.confusion_matrix(test_data.labels, predictions)
clr = classification_report(test_data.labels, predictions, target_names=CLASS_NAMES)

print("Test Accuracy: {:.3f}%".format(acc * 100))

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
plt.xticks(ticks= np.arange(2) + 0.5, labels=CLASS_NAMES)
plt.yticks(ticks= np.arange(2) + 0.5, labels=CLASS_NAMES)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

predictions = np.argmax(model.predict(val_data), axis=1)

acc = accuracy_score(val_data.labels, predictions)
cm = tf.math.confusion_matrix(val_data.labels, predictions)
clr = classification_report(val_data.labels, predictions, target_names=CLASS_NAMES)

print("Validation Accuracy: {:.3f}%".format(acc * 100))

plt.figure(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
plt.xticks(ticks= np.arange(2) + 0.5, labels=CLASS_NAMES)
plt.yticks(ticks= np.arange(2) + 0.5, labels=CLASS_NAMES)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

print("Classification Report:\n----------------------\n", clr)

from tensorflow.keras.preprocessing.image import load_img, img_to_array
# from tf.keras.utils.load_img
from keras.preprocessing import image
from tensorflow.keras.preprocessing import image

# img = image.load_img("/content/val/yes/Y169.jpg", target_size = (224,224))
img = image.load_img("/content/train/no/17 no.jpg", target_size = (224,224))


i = image.img_to_array(img)/255   #dividing by 255 for normalizing the image
# i = preprocess_input(i)
input_arr = np.array([i])
input_arr.shape
# input_arr = np.expand_dims(input_arr, axis = 0 )
# pred = model.predict(input_arr)[0][0]
# pred = np.argmax(model.predict(input_arr))


pred = (model.predict(input_arr) > 0.5)*1
# pred

# ploting image
plt.imshow(input_arr[0])
plt.title("input image")
plt.show()


# path = "/content/val/yes/Y169.jpg"

if pred == 0:
  print("The MRI image NOT HAVING a tumor")
else:
  print("The MRI image HAVING a tumor")

train_data.class_indices

